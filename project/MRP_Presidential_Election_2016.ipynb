{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Elections with \"Mister P\" (MRP, multi-level regression and post-stratification)\n",
    "\n",
    "## Andrew Enfield, University of Washington Data 512 Autumn 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I used Bayesian multi-level regression and post-stratification (MRP), and Python and [PyMC3](https://github.com/pymc-devs/pymc3) to adjust an unrepresentative sample of election preferences and predict the outcome of the 2016 US Presidential election. My results don't match the survey from which I used the raw data, possibly because I haven't used enough predictors (in the interest of simplicity). Nonetheless, the code and explanation show an attempt at learning and applying MRP using a language and MCMC framework that I haven't found used for such a purpose before. \n",
    "\n",
    "**NOTE:** I'm new to this concept and PyMC3, and did this work without review. I also spent a relatively minimal amount of time on this project, as it was just a portion of the work for a particular class. If you happen upon this project and see things I did incorrectly or can do better, please let me know - it'll help me continue to learn. There's a non-exhaustive list of many things that I could do to improve this work in the Discussion section at the end of the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background and related work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most statistics assume implicitly or explicitly that the sample on which the statistic or inference is applied is _representative_ of the population of interest. I've found personally at least that this assumption is often violated: to a first approximation, I'm more likely to be correct when I assume that a sample is _not representative_.\n",
    "\n",
    "An unrepresentative sample can cause the results based on the sample to be incorrect, and can have other bad effects, including missing signal from under-represented groups (for example, people that are harder to find in order to sample). The degree to which this is a problem in practice depends, at least, on the degree to which the sample is not representative and on the importance of the inference made based on the sample.\n",
    "\n",
    "While a properly-run randomized controlled trial (RCT) can guarantee a representative sample, it's not always practical to run such an experiment. Furthermore, requiring an RCT automatically excludes numerous convenience or other samples. This is especially unfortunate given the explosion in recent years of accessible data that likely contains information but that isn't known to be representative of a larger population.\n",
    "\n",
    "It is possible to adjust unrepresentative data after the fact and generate results that more closely hew to the results that would have been obtained from a representative sample. This isn't a silver bullet, and can be difficult, but when done successfully it can make results more useful. The New York Times article [How One 19-Year-Old Illinois Man Is Distorting National Polling Averages](https://www.nytimes.com/2016/10/13/upshot/how-one-19-year-old-illinois-man-is-distorting-national-polling-averages.html) describes general issues with unrepresentative samples as well as with adjusting these samples.\n",
    "\n",
    "In more detail, two of multiple methods that can be used to adjust samples are [propensity score matching](https://en.wikipedia.org/wiki/Propensity_score_matching) and [post-stratification](https://onlinecourses.science.psu.edu/stat506/node/29). I use post-stratification in this project.\n",
    "\n",
    "Generally, post-stratification involves three steps:\n",
    "\n",
    "1. Dividing the population into \"cells\", one for each combination of values in the variables of interest. For example, in this notebook I know the sex, race/ethnicity, and state for each respondent. The Pew Research Center source data (documented in the [README](README.md)) has two values for sex, five values for race/ethnicity, and 51 values for state (including the District of Columbia). This makes for 2 x 5 x 51 = 510 combinations of values, or cells. \n",
    "\n",
    "2. For each cell, estimating the statistic in question for observations with the characteristics for that cell and finding the proportion of the overall population in that cell. I estimate the probability of people with the particular combination of sex, race/ethnicity, and state expressing a preference for Trump, with the complement of that probability being the preference for Clinton, using the Pew Research Center poll data. I obtain the proportion of the US population for each cell from the US Census Bureau's Current Population Survey (CPS). Then, I calculate the contribution of that cell to the overall statistic by multiplying the estimated statistic and the population.\n",
    "\n",
    "3. Calculate the final estimate as an average of all cells, weighted by the population in each cell. \n",
    "\n",
    "In this project I use a particular approach called \"multi-level regression and post-stratification\" (MRP), which is distinguished by its use of Bayesian multi-level (or hierarchical) regression. As related to the previous steps, this is the particular implementation of the \"estimate the statistic in question\" part of step two above. Bayesian regression uses models where the regression coefficients are defined as parameters to be estimated based on the observed data as well as pre-chosen probability distributions using Bayes' Rule. The \"multi-level\" part of the implementation refers to the use of additional parameters that are also estimated and that are \"above\" or shared by multiple lower-level parameters. The model defined below, for example, defines a regression coefficient/parameter for each state, as well as a higher level \"hyper\" parameter that is shared by all states. The value of this higher level parameter depends on the values of all of the lower level parameters, generally in proportion to the amount of data associated with each lower level parameter. As a result, parameters associated with smaller amounts of data are automatically - by Bayes' Rule - \"shrunk\" toward the mean value, while parameters associated with more data are defined primarily by the data itself.\n",
    "\n",
    "Note also that while Bayesian multi-level regression has advantages, any approach - including simple OLS logistic regression - could be used to find the estimate, and in fact I compare results from both Bayesian regression and OLS logistic regression below.\n",
    "\n",
    "MRP has been implemented and popularized by academics including Andrew Gelman, and others, including via the following papers and blog posts (this is a non-exhaustive list):\n",
    "- [Forecasting elections with non-representative polls](http://www.stat.columbia.edu/~gelman/research/published/forecasting-with-nonrepresentative-polls.pdf); Wang, Rothschild, Goel, Gelman.\n",
    "- [Deep Interactions with MRP: Election Turnout and Voting Patterns Among Small Electoral Subgroups](http://www.stat.columbia.edu/~gelman/research/published/misterp.pdf); Ghitza, Gelman.\n",
    "- [Estimating State Public Opinion With Multi-Level Regression and Poststratification using R](http://www.princeton.edu/~jkastell/MRP_primer/mrp_primer.pdf); Kastellec, Lax, Phillips.\n",
    "- [We Gave Four Good Pollsters the Same Raw Data. They Had Four Different Results.](https://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html); Cohn.\n",
    "- [Mister P can solve problems with survey weighting](http://andrewgelman.com/2016/10/12/31398/); Gelman.\n",
    "- [Mister P: Whatâ€™s its secret sauce?](http://andrewgelman.com/2013/10/09/mister-p-whats-its-secret-sauce/); Gelman.\n",
    "\n",
    "There are a variety of libraries and packages for doing Bayesian inference and analysis. In this project I use [PyMC3](https://github.com/pymc-devs/pymc3), which is a \"Python package for Bayesian statistical modeling and Probabilistic Machine Learning which focuses on advanced Markov chain Monte Carlo and variational fitting algorithms.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This (long) section loads and prepares the data, estimates probabilities, and generates predictions.\n",
    "\n",
    "The code requires the following non-stock libraries - some come with distributions like Anaconda (pandas, for example); others should be installed as directed by project documentation (PyMC3).\n",
    "- pandas\n",
    "- NumPy\n",
    "- Seaborn\n",
    "- Matplotlib\n",
    "- PyMC3\n",
    "- Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "# to generate the full matrix of input data from a list of possibilities\n",
    "import itertools \n",
    "\n",
    "# to sanity check some pymc3 results against normal logistic regression results\n",
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to enable viewing longer Series and DataFrame instances\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load and prepare Pew poll data with candidate preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poll data is from the Pew Research Center and is documented in more detail in the [README](README.md). This data contains demographic information and the candidate each person prefers. Here I load a subset of the full data set with just the fields I need to do MRP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2583, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.read_csv('pew_poll.csv')\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sex</th>\n",
       "      <th>q10horseGP</th>\n",
       "      <th>race3m1</th>\n",
       "      <th>race3m2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Male</td>\n",
       "      <td>Trump/lean Trump</td>\n",
       "      <td>White (e.g., Caucasian, European, Irish, Itali...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>Female</td>\n",
       "      <td>Clinton/lean Clinton</td>\n",
       "      <td>White (e.g., Caucasian, European, Irish, Itali...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.264706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       state     sex            q10horseGP  \\\n",
       "0  Minnesota    Male      Trump/lean Trump   \n",
       "1   Delaware  Female  Clinton/lean Clinton   \n",
       "\n",
       "                                             race3m1 race3m2    weight  \n",
       "0  White (e.g., Caucasian, European, Irish, Itali...     NaN  2.088235  \n",
       "1  White (e.g., Caucasian, European, Irish, Itali...     NaN  1.264706  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The readme.txt file that comes with the Pew Research Center data explains how to convert the data's race3m1 and race3m2 fields into a 'racecmb' field. The next bit of code implements the text as Python code, and generates a racecmb field in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "racethn_to_index = {\n",
    "    \"White (e.g., Caucasian, European, Irish, Italian, Arab, Middle Eastern)\": 1,\n",
    "    \"Black or African-American (e.g., Negro, Kenyan, Nigerian, Haitian)\": 2,\n",
    "    \"Asian or Asian-American (e.g., Asian Indian, Chinese, Filipino, Vietnamese or other Asian origin groups)\": 3,\n",
    "    \"Some other race (SPECIFY____ IF NEEDED: What race or races is that?)\": 4,\n",
    "    \"Native American/American Indian/Alaska Native (VOL.)\": 5,\n",
    "    \"Pacific Islander/Native Hawaiian (VOL.)\": 6,\n",
    "    \"Hispanic/Latino (VOL.) (e.g., Mexican, Puerto Rican, Cuban)\": 7,\n",
    "    \"Don't know (VOL.)\": 8,\n",
    "    \"Refused (e.g., non-race answers like American, Human, purple) (VOL.)\": 9\n",
    "}\n",
    "\n",
    "d['race3m1_index'] = d['race3m1'].map(racethn_to_index)\n",
    "d['race3m2_index'] = d['race3m2'].map(racethn_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_racecmb(row):\n",
    "    if ((row['race3m2_index'] > 0) & (row['race3m2_index'] < 8)):\n",
    "        return 'Mixed Race'\n",
    "    elif (row['race3m1_index'] == 1):\n",
    "        return 'White'\n",
    "    elif (row['race3m1_index'] == 2):\n",
    "        return 'Black or African-American'\n",
    "    elif (row['race3m1_index'] == 3):\n",
    "        return 'Asian or Asian-American'\n",
    "    elif (row['race3m1_index'] >= 4 & row['race3m1_index'] <= 7):\n",
    "        return 'Or some other race'\n",
    "    elif ((row['race3m1_index'] >= 8) & (row['race3m1_index'] <= 9)):\n",
    "        return 'DonÂ’t know/Refused (VOL.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['racecmb'] = d.apply(get_racecmb, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White                        1935\n",
       "Black or African-American     258\n",
       "Or some other race            230\n",
       "Asian or Asian-American        83\n",
       "Mixed Race                     77\n",
       "Name: racecmb, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['racecmb'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The q10horseGP field contains the candidate preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clinton/lean Clinton     972\n",
       "Trump/lean Trump         858\n",
       "Not registered           466\n",
       "Johnson/lean Johnson     124\n",
       "DK-refused to lean        76\n",
       "Stein/lean Stein          57\n",
       "Other-refused to lean     30\n",
       "Name: q10horseGP, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['q10horseGP'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm only modeling a binary outcome, so I'll filter to just the rows with people that express a preference for Clinton or Trump. (See the Discussion section below for more about how I could improve the handling of people with non-Clinton and non-Trump preferences.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_only = d[(d['q10horseGP'] == 'Clinton/lean Clinton') | \n",
    "           (d['q10horseGP'] == 'Trump/lean Trump')]\n",
    "d_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Clinton/lean Clinton    972\n",
       "Trump/lean Trump        858\n",
       "Name: q10horseGP, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_only['q10horseGP'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the next few lines show, I only have 50 states in the data, even though we'd expect 51, including D.C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_only['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California              158\n",
       "Texas                   133\n",
       "Florida                 123\n",
       "New York                121\n",
       "Pennsylvania             75\n",
       "Ohio                     72\n",
       "New Jersey               68\n",
       "Georgia                  62\n",
       "Michigan                 61\n",
       "North Carolina           61\n",
       "Virginia                 60\n",
       "Illinois                 57\n",
       "Minnesota                48\n",
       "Arizona                  45\n",
       "Washington               45\n",
       "Wisconsin                43\n",
       "Tennessee                37\n",
       "Missouri                 34\n",
       "Kentucky                 34\n",
       "South Carolina           33\n",
       "Indiana                  33\n",
       "Colorado                 33\n",
       "Maryland                 30\n",
       "Oregon                   29\n",
       "Louisiana                28\n",
       "Massachusetts            28\n",
       "Oklahoma                 26\n",
       "Alabama                  22\n",
       "Iowa                     19\n",
       "Kansas                   19\n",
       "Idaho                    18\n",
       "Nevada                   18\n",
       "Connecticut              17\n",
       "West Virginia            15\n",
       "Utah                     15\n",
       "Mississippi              14\n",
       "Arkansas                 12\n",
       "District of Columbia     11\n",
       "Maine                    10\n",
       "Nebraska                 10\n",
       "Hawaii                    8\n",
       "Delaware                  8\n",
       "New Mexico                8\n",
       "North Dakota              7\n",
       "Rhode Island              7\n",
       "Alaska                    5\n",
       "New Hampshire             4\n",
       "Vermont                   3\n",
       "Wyoming                   2\n",
       "Montana                   1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_only['state'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no observations from South Dakota in the data. (There was a row before I filtered to just people with Clinton/Trump preferences.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sex</th>\n",
       "      <th>q10horseGP</th>\n",
       "      <th>race3m1</th>\n",
       "      <th>race3m2</th>\n",
       "      <th>weight</th>\n",
       "      <th>race3m1_index</th>\n",
       "      <th>race3m2_index</th>\n",
       "      <th>racecmb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [state, sex, q10horseGP, race3m1, race3m2, weight, race3m1_index, race3m2_index, racecmb]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_only[d_only['state'] == 'South Dakota']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I don't have any rows in our two-party data with South Dakota, absent any extra work on our part, I won't have an indicator variable for this state, which'll make it harder to do things with the state later, including to get state-level probabilities. \n",
    "\n",
    "The following code creates a dataframe with a row per respondent, with indicator variables for each state, including South Dakota (which I add manually, and which is always zero). The models use these indicator fields as part of estimating the probability of voting for Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 51)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add South Dakota, using the same index to make sure I don't add extra cols (there may be a better way to do this)\n",
    "state_dummies = pd.concat([pd.get_dummies(d_only['state']), \n",
    "                           pd.Series(name='South Dakota', data=np.repeat(0, len(d_only)), index=d_only.index)], axis=1)\n",
    "# alphabetize to put SD in the right spot\n",
    "state_dummies = state_dummies.reindex(sorted(state_dummies.columns), axis=1)\n",
    "state_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_count = len(state_dummies.columns.values)\n",
    "state_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll create a dict that maps the state's number - which I see in, for example, the coefficients generated by the models below - to the state's name. I use this dict below to generate the complete set of cells, for prediction/post-stratification. It's also useful to do focused research on particular IDs, since it shows the particular state for each ID in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Alabama',\n",
       " 1: 'Alaska',\n",
       " 2: 'Arizona',\n",
       " 3: 'Arkansas',\n",
       " 4: 'California',\n",
       " 5: 'Colorado',\n",
       " 6: 'Connecticut',\n",
       " 7: 'Delaware',\n",
       " 8: 'District of Columbia',\n",
       " 9: 'Florida',\n",
       " 10: 'Georgia',\n",
       " 11: 'Hawaii',\n",
       " 12: 'Idaho',\n",
       " 13: 'Illinois',\n",
       " 14: 'Indiana',\n",
       " 15: 'Iowa',\n",
       " 16: 'Kansas',\n",
       " 17: 'Kentucky',\n",
       " 18: 'Louisiana',\n",
       " 19: 'Maine',\n",
       " 20: 'Maryland',\n",
       " 21: 'Massachusetts',\n",
       " 22: 'Michigan',\n",
       " 23: 'Minnesota',\n",
       " 24: 'Mississippi',\n",
       " 25: 'Missouri',\n",
       " 26: 'Montana',\n",
       " 27: 'Nebraska',\n",
       " 28: 'Nevada',\n",
       " 29: 'New Hampshire',\n",
       " 30: 'New Jersey',\n",
       " 31: 'New Mexico',\n",
       " 32: 'New York',\n",
       " 33: 'North Carolina',\n",
       " 34: 'North Dakota',\n",
       " 35: 'Ohio',\n",
       " 36: 'Oklahoma',\n",
       " 37: 'Oregon',\n",
       " 38: 'Pennsylvania',\n",
       " 39: 'Rhode Island',\n",
       " 40: 'South Carolina',\n",
       " 41: 'South Dakota',\n",
       " 42: 'Tennessee',\n",
       " 43: 'Texas',\n",
       " 44: 'Utah',\n",
       " 45: 'Vermont',\n",
       " 46: 'Virginia',\n",
       " 47: 'Washington',\n",
       " 48: 'West Virginia',\n",
       " 49: 'Wisconsin',\n",
       " 50: 'Wyoming'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_number_to_name = dict(list(zip(range(0,51), sorted(state_dummies.columns.values))))\n",
    "state_number_to_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll create a single dataframe with indicator variables for each field. I need this for all categorical variables, which are all the variables - sex, race, state - that currently exist in this analysis. \n",
    "\n",
    "Sex has a single indicator variable, called 'Male', while race and state have an indicator variable per value. That is, a value of 0 for 'Male' indicates female while a 1 indicates male. Each individual race and state value has its own indicator field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 57)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_only_dummies = pd.concat([pd.get_dummies(d_only['sex'], drop_first=True),\n",
    "                            pd.get_dummies(d_only['racecmb']),\n",
    "                            state_dummies], axis=1)\n",
    "d_only_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "      <th>Asian or Asian-American</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Mixed Race</th>\n",
       "      <th>Or some other race</th>\n",
       "      <th>White</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Arkansas</th>\n",
       "      <th>...</th>\n",
       "      <th>South Dakota</th>\n",
       "      <th>Tennessee</th>\n",
       "      <th>Texas</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Male  Asian or Asian-American  Black or African-American  Mixed Race  \\\n",
       "0     1                        0                          0           0   \n",
       "1     0                        0                          0           0   \n",
       "\n",
       "   Or some other race  White  Alabama  Alaska  Arizona  Arkansas   ...     \\\n",
       "0                   0      1        0       0        0         0   ...      \n",
       "1                   0      1        0       0        0         0   ...      \n",
       "\n",
       "   South Dakota  Tennessee  Texas  Utah  Vermont  Virginia  Washington  \\\n",
       "0             0          0      0     0        0         0           0   \n",
       "1             0          0      0     0        0         0           0   \n",
       "\n",
       "   West Virginia  Wisconsin  Wyoming  \n",
       "0              0          0        0  \n",
       "1              0          0        0  \n",
       "\n",
       "[2 rows x 57 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_only_dummies[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data frames of all cells (indicator and otherwise), for use as input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately I want a prediction - the probability of voting for Trump and Clinton - for each cell: for each combination of values in the features on which I'm stratifying. I'll create two data frames here, each with one row per cell: one with the values themselves, and one with indicator/dummy variables (for use when predicting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Female', 'Asian or Asian-American', 'Alabama'),\n",
       " ('Female', 'Asian or Asian-American', 'Alaska')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cells_list = list(itertools.product(np.sort(d_only['sex'].unique()), \n",
    "                                        np.sort(d_only['racecmb'].unique()),\n",
    "                                        sorted(state_number_to_name.values())))\n",
    "all_cells_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_cells_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>racecmb</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Asian or Asian-American</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>Asian or Asian-American</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex                  racecmb    state\n",
       "0  Female  Asian or Asian-American  Alabama\n",
       "1  Female  Asian or Asian-American   Alaska"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cells = pd.DataFrame(all_cells_list, columns=['sex','racecmb','state'])\n",
    "all_cells[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>racecmb_Asian or Asian-American</th>\n",
       "      <th>racecmb_Black or African-American</th>\n",
       "      <th>racecmb_Mixed Race</th>\n",
       "      <th>racecmb_Or some other race</th>\n",
       "      <th>racecmb_White</th>\n",
       "      <th>state_Alabama</th>\n",
       "      <th>state_Alaska</th>\n",
       "      <th>state_Arizona</th>\n",
       "      <th>state_Arkansas</th>\n",
       "      <th>...</th>\n",
       "      <th>state_South Dakota</th>\n",
       "      <th>state_Tennessee</th>\n",
       "      <th>state_Texas</th>\n",
       "      <th>state_Utah</th>\n",
       "      <th>state_Vermont</th>\n",
       "      <th>state_Virginia</th>\n",
       "      <th>state_Washington</th>\n",
       "      <th>state_West Virginia</th>\n",
       "      <th>state_Wisconsin</th>\n",
       "      <th>state_Wyoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_Male  racecmb_Asian or Asian-American  \\\n",
       "0         0                                1   \n",
       "1         0                                1   \n",
       "2         0                                1   \n",
       "\n",
       "   racecmb_Black or African-American  racecmb_Mixed Race  \\\n",
       "0                                  0                   0   \n",
       "1                                  0                   0   \n",
       "2                                  0                   0   \n",
       "\n",
       "   racecmb_Or some other race  racecmb_White  state_Alabama  state_Alaska  \\\n",
       "0                           0              0              1             0   \n",
       "1                           0              0              0             1   \n",
       "2                           0              0              0             0   \n",
       "\n",
       "   state_Arizona  state_Arkansas      ...        state_South Dakota  \\\n",
       "0              0               0      ...                         0   \n",
       "1              0               0      ...                         0   \n",
       "2              1               0      ...                         0   \n",
       "\n",
       "   state_Tennessee  state_Texas  state_Utah  state_Vermont  state_Virginia  \\\n",
       "0                0            0           0              0               0   \n",
       "1                0            0           0              0               0   \n",
       "2                0            0           0              0               0   \n",
       "\n",
       "   state_Washington  state_West Virginia  state_Wisconsin  state_Wyoming  \n",
       "0                 0                    0                0              0  \n",
       "1                 0                    0                0              0  \n",
       "2                 0                    0                0              0  \n",
       "\n",
       "[3 rows x 57 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove sex_Female since I only need one col for sex\n",
    "all_cells_dummies = pd.get_dummies(all_cells).drop('sex_Female', 1)\n",
    "all_cells_dummies[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate voter preferences using multi-level regression and PyMC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm ready to define a multi-level/hierarchical model to estimate plausible values, given the data, for parameters I define in the model. Specifically, I'll define the model as a multiple logistic regression model so that I can estimate plausible coefficients for sex, each race/ethnicity value, and each state. Then I'll use PyMC3 to generate an MCMC chain, and extract the mean and credible intervals for the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need a vector with the observed data, which is the preference for Clinton (0) and Trump (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(972, 858)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_obs_categorical = pd.Categorical(d_only['q10horseGP'])\n",
    "y_obs = y_obs_categorical.codes\n",
    "\n",
    "sum(y_obs == 0), sum(y_obs == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Trump/lean Trump, Clinton/lean Clinton, Trump/lean Trump, Trump/lean Trump, Clinton/lean Clinton, ..., Trump/lean Trump, Clinton/lean Clinton, Clinton/lean Clinton, Clinton/lean Clinton, Clinton/lean Clinton]\n",
       "Length: 1830\n",
       "Categories (2, object): [Clinton/lean Clinton, Trump/lean Trump]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_obs_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I'll give names to the specific columns I care about when training the model, for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1830,), (1830, 5), (1830, 51))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals_sex = d_only_dummies.values[:,0]\n",
    "vals_racecmb = d_only_dummies.values[:,1:6]\n",
    "vals_state = d_only_dummies.values[:,6:]\n",
    "\n",
    "vals_sex.shape, vals_racecmb.shape, vals_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And define the logistic function so that I can extract probabilities from the results of the linear model, while the I'm generating the chain, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describing Bayesian inference and MCMC generally is outside the scope of this paper, but I will try to summarize the model briefly. I'll also say that there's nothing particularly special about this model, in terms of Bayesian inference: it's a relatively standard hierarchical/multi-level Bayesian logistic regression model.\n",
    "\n",
    "The next block of code defines the model using PyMC3. The model includes a 'mu' parameter that is just the result of a  typical linear equation, with an alpha/intercept, and with a coefficient for each indicator variable (in this example, one of 57 variables: one for sex, five for race/ethnicity, and 51 for state). These coefficients are named beta_sex, beta_race (an array of size five), and beta_state (an array of size 51).\n",
    "\n",
    "Every PyMC3 model needs to tie the parameters to the data. This model connects the result of the mu parameter, transformed using the standard logistic function (so the result is a probability from 0 to 1) and named 'theta', to the data using a Bernoulli likelihood function. Because of this linkage, when PyMC3 generates the MCMC chain the values of the parameters are those that are likely given the data (and the model structure).\n",
    "\n",
    "In addition, this model defines shared hierarchical 'hyper' parameters, called 'mu_race' and 'mu_state'. These parameters define the prior distribution for all of the beta_race and beta_state parameters, respectively. This structure shares information between all race and state parameters, so that, for example, data from one state informs the values for all other states. This information sharing happens in proportion to the amount of data for each value - that is, states, for example, that have many observations contribute more to the shared and general state parameter while states that have little or no observations contribute minimally or not at all. Furthermore, state-specific coefficient parameters for states that have lots of data are informed minimally by the shared parameter, and state-specific coefficient parameters for states that have little to no data are defined primarily by the shared hyper parameter. Put differently, parameters for which I have a lot of data - say, the beta_state parameter for California - are defined mainly by the data. Parameters for which I have little or no data - like Montana, South Dakota, etc. - are defined primarily by the value of the shared hyper parameter.\n",
    "\n",
    "I've included some additional more detailed notes in comments in the code.\n",
    "\n",
    "Also note that I tried a number of different models, with different parameters, different priors, and other changes, in the [ProjectResearch](ProjectResearch.ipynb) notebook. I only use a single model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model_complete:\n",
    "    # intercept parameter (not clear that the model needs this)\n",
    "    alpha = pm.Normal('alpha', mu=0, sd=10)\n",
    "    \n",
    "    # single sex coefficient parameter, fixed mu and SD (no sharing needed)\n",
    "    beta_sex = pm.Normal('beta_sex', mu=0, sd=2)\n",
    "    \n",
    "    # five beta_race coefficient params, and mu_race and sigma_race as hierarchical priors \n",
    "    mu_race = pm.Normal('mu_race', mu=0, sd=10)\n",
    "    sigma_race = pm.HalfCauchy('sigma_race', 5)\n",
    "    beta_race = pm.Normal('beta_race', mu=mu_race, sd=sigma_race, \n",
    "                          shape=len(d_only['racecmb'].unique()))\n",
    "    \n",
    "    # 51 beta_state coefficient params, and mu_state as a hierachical prior (fixed SD for simplicity)\n",
    "    mu_state = pm.Normal('mu_state', mu=0, sd=10)\n",
    "    beta_state = pm.Normal('beta_state', mu=mu_state, sd=1, \n",
    "                          shape=state_count)\n",
    "    \n",
    "    # result of linear regression\n",
    "    mu = alpha + \\\n",
    "         vals_sex * beta_sex + \\\n",
    "         pm.math.dot(vals_racecmb, beta_race) + \\\n",
    "         pm.math.dot(vals_state, beta_state)\n",
    "\n",
    "    # transform linear result to 0-1 range using logistic function\n",
    "    theta = pm.Deterministic('theta', standard_logistic(mu))\n",
    "    \n",
    "    # also, calculate the probability as part of the chain (can't use aggregate stats - must\n",
    "    # calc based on each step in the chain, since each step is a plausible set of values)\n",
    "    all_cells_values_matrix = all_cells_dummies.values\n",
    "    probs = pm.Deterministic('probs', standard_logistic(alpha + \\\n",
    "                 all_cells_values_matrix[:,0] * beta_sex + \\\n",
    "                 pm.math.dot(all_cells_values_matrix[:,1:6], beta_race) + \\\n",
    "                 pm.math.dot(all_cells_values_matrix[:,6:], beta_state)))\n",
    "\n",
    "    # link model to data\n",
    "    y = pm.Bernoulli('y', theta, observed=y_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I can use PyMC3 to generate a set of plausible parameter values. The sample call below generates 1000 plausible combinations of values, after throwing away the first 1000 during burn-in/tuning (n_init is the number of initialization iterations). As is common with MCMC libraries, this takes a while - on my laptop, typically 10 minutes or so.\n",
    "\n",
    "As part of my research, I tried different numbers of samples - more samples can give more resolution in the results, but take longer to generate. I stayed with the values below as they represent an empirically good mix between reasonable results and CPU cycles to generate. Also, the sample run shows a 'UserWarning' that 'Chain 0 reached the maximum tree depth'. Given the relative simplicity of the model, this warning in this context may be a false positive or an indication that the sampling isn't as efficient as it could be given the model and data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "  7%|â–‹         | 139/2000 [00:27<07:27,  4.15it/s]/Users/andrewenfield/miniconda3/envs/anaconda/lib/python3.6/site-packages/pymc3/step_methods/hmc/nuts.py:429: UserWarning: Chain 0 contains only 0 samples.\n",
      "  % (self._chain_id, n))\n",
      "/Users/andrewenfield/miniconda3/envs/anaconda/lib/python3.6/site-packages/pymc3/step_methods/hmc/nuts.py:431: UserWarning: Step size tuning was enabled throughout the whole trace. You might want to specify the number of tuning steps.\n",
      "  warnings.warn('Step size tuning was enabled throughout the whole '\n",
      "/Users/andrewenfield/miniconda3/envs/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(43)\n",
    "\n",
    "with model_complete:\n",
    "    trace_complete = pm.sample(1000, n_init=50000, tune=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine MCMC diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is the case with MCMC, after generating the sample, which represents the posterior distribution, I want to examine the results of the MCMC run using diagnostic plots and numbers.\n",
    "\n",
    "Because these are diagnostic plots - not plots to communicate results, for example - I don't spend much time marking the plots up to be easy for all to understand. Instead, I rely mainly on the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varnames_model_complete = ['alpha', 'beta_sex', \n",
    "                           'mu_race', 'sigma_race', 'beta_race',\n",
    "                           'mu_state', 'beta_state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll examine the distribution of the values for the parameters - on the left in the plots below - and the degree to which the value for each parameter changes as the chain progresses - on the right. Ideally the plots on the right jump around more or less randomly - this is the case for most of the parameters (alpha, beta_sex, etc.) but not so much especially for the state parameters. I think this is likely due to the way the model is parameterized in combination with the specific data - even despite this I still get results that are consistent and don't change much (except for the standard MCMC variability) across different runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace_complete, varnames_model_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the 95% credible intervals for each parameter - i.e., the range of values that is required to capture the middle 95% of the sample values. The darker lines in the middle show the interquartile range and the dot shows the mean. (While these might _sound_ something like 95% confidence intervals in null hypothesis significance testing, they're actually completely different: I have, here, 1000 samples, each of which has a plausible combination of values for all 57 parameters. I can use this full set of data to get an idea of how much each parameter varies by simply plotting the mean, interquartile range, and 95% credible interval, for each parameter, as I've done below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,11))\n",
    "pm.forestplot(trace_complete, varnames_model_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also calculated the probabilities for each of the 510 cells at each of the 1000 steps in the chain, so I could get an idea of how much the probability (of voting for Trump) varies. The plot below has an x axis range from 0 to 1 - the closer the plot is to zero, the more likely people in that cell are to vote for Clinton; the closer the probability is to 1, the more likely people are to vote for Trump.\n",
    "\n",
    "While the graphic below takes up a lot of space, it's worth including because of the amount of information in the plot. The chart below is the only part of this paper, at least, that shows visually the degree to which the probabilities for the different cells vary compared to each other. It's interesting, and expected, for example, how much wider the credible intervals are for cells for which the poll provides relatively little information - compare the rows for many of the California cells, which are narrow, to the rows for a state like Montana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,80))\n",
    "pm.forestplot(trace_complete, ['probs'], ylabels=all_cells_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally the less parameter values are correlated with the previous values (i.e., the less they are auto-correlated), the more efficient the sampling process. I won't lengthen this notebook with the following diagnostic plots, and will just say that the parameters show relatively little auto-correlation. (This is the case at least with this particular random seed - with some other seeds the auto-correlation for state fields is worse; this doesn't appear to hurt the final results in ways that I can determine, but it is evidence that I might want more samples if I was to work with the data further.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pm.autocorrplot(trace_complete, varnames_model_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here are the coefficient values and ranges, already shown above graphically, as a table of numbers. I haven't printed out the 510 probabilities, in the interest of space. I could do this easily by running the code below with the varnames_model_complete variable replaced by the '['probs']'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pm.df_summary(trace_complete, varnames_model_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and add probabilities per cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the point of the above model is to generate probabilities for each cell. I calculate the probabilities here, for each of the 510 cells, and then append the probabilities to the all_cells dataframe I'm using to keep track of each cell.\n",
    "\n",
    "For the sake of simplicity, I calculate just a single probability for each cell, using the average/mean value of the coefficient (from all 1000 sample values). The data in the chain would make it easy to also show the uncertainty in the probability, but I'm not going to do that here for now, for the sake of simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_with_matrix(values_matrix, trace_data, varnames, add_intercept=False):\n",
    "    \"\"\"\n",
    "    Return the probability of the cell taking the value of 1 (in this code, this means the\n",
    "    probability of voting for Trump).\n",
    "    \n",
    "    values_matrix: a matrix of values denoting the cell, as a set of indicator fields\n",
    "    trace_data: MCMC chain of samples, from PyMC3\n",
    "    varnames: variables in the chain, should be the same size as the width of values_matrix\n",
    "    add_intercept: whether to add a column of 1s as the first column; useful when the trace \n",
    "    has an alpha intercept.\n",
    "    \"\"\"\n",
    "    if add_intercept:\n",
    "        # add a column at the beginning with all ones, to match up w/ something like \n",
    "        # an alpha param\n",
    "        values_matrix = np.c_[np.ones(len(values_matrix)), values_matrix]\n",
    "\n",
    "    mean_vals = pm.df_summary(trace_data, varnames)['mean'].values\n",
    "\n",
    "    # dot product matrix multiplication FTW, to get 510 probabilities in one fell swoop\n",
    "    mu = np.dot(values_matrix, mean_vals)\n",
    "\n",
    "    prob = standard_logistic(mu)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = classify_with_matrix(all_cells_dummies, trace_complete,\n",
    "                            ['alpha','beta_sex','beta_race','beta_state'], add_intercept=True)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells['trump_prob'] = probs\n",
    "all_cells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_cells[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also keep the probability data from the chain itself, for comparison and as a way to show uncertainty. This uses the set of 510 parameters defined in the model with the name 'prob'. \n",
    "\n",
    "Note the difference between the 'trump_prob' and 'mean' columns. The former is calculated by multiplying the indicator variables for each cell with the mean values of the parameters estimated using MCMC. The latter is calculated as the mean of probability values recorded while chain is generated - i.e., in contrast to the 'trump_prob' field, this is the mean of the 1000 probability values calculated while generating 1000 samples from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_cells_with_trace = pd.concat([all_cells, pm.df_summary(trace_complete, ['probs']).reset_index(drop=True)], axis=1)\n",
    "all_cells_with_trace[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare CPS data for population calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, I now have estimates for the probability of voting for Trump for each cell. The other data I need to post-stratify and generate an overall prediction is the population in each cell. It's this population that I'll use to weight/adjust the probabilities.\n",
    "\n",
    "The population data is from the US Census and IPUMS at the University of Minnesota and is documented in more detail in the [README](README.md). This data, from the ASEC 2016 data set, contains a row per person surveyed, with the person's sex, race/ethnicity, and state. Each row also contains a weight column, called WTSUPP, that shows the degree to which that person's obvservation should be weighted so that the end result is representative of the US population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pop = pd.read_csv('cps_population.csv')\n",
    "d_pop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_pop[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values from the CPS need to match the values from the Pew poll data. I examined the sex and state values, and they're fine and need no work. For race/ethnicity, the CPS provides data at a much more granular level, so I'll map here to the five values used in the poll data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cps_race_to_pew_racecmb = {\n",
    "    'White':'White',\n",
    "    'Black/Negro':'Black or African-American',\n",
    "    'Asian only':'Asian or Asian-American',\n",
    "    'American Indian/Aleut/Eskimo':'Or some other race',\n",
    "    'White-American Indian':'Mixed Race',\n",
    "    'White-Black':'Mixed Race',\n",
    "    'Hawaiian/Pacific Islander only':'Or some other race',\n",
    "    'White-Asian':'Mixed Race',\n",
    "    'White-Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'Black-American Indian':'Mixed Race',\n",
    "    'Asian-Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'White-Black-American Indian':'Mixed Race',\n",
    "    'White-Asian-Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'Black-Asian':'Mixed Race',\n",
    "    'White-Black-Asian':'Mixed Race',\n",
    "    'Four or five races, unspecified':'Mixed Race',\n",
    "    'Black-Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'White-American Indian-Asian':'Mixed Race',\n",
    "    'Two or three races, unspecified':'Mixed Race',\n",
    "    'American Indian-Asian':'Mixed Race',\n",
    "    'White-Black-American Indian-Asian':'Mixed Race',\n",
    "    'White-Black--Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'White-American Indian-Asian-Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'White-American Indian-Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'American Indian-Hawaiian/Pacific Islander':'Mixed Race',\n",
    "    'Black-American Indian-Asian':'Mixed Race'\n",
    "}\n",
    "map_cps_race_to_pew_racecmb\n",
    "\n",
    "d_pop['mapped_racecmb'] = d_pop['RACE'].map(map_cps_race_to_pew_racecmb)\n",
    "\n",
    "d_pop['mapped_racecmb'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate predicted votes based on preferences and cell populations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I'll augment the by-cell data first with the population for that cell, and then with the predicted number of Clinton and Trump votes.\n",
    "\n",
    "The population for each cell is the sum of the WTSUPP values for every person with the characteristics of that cell. I'll first calculate the populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_by_cell = d_pop.groupby(['SEX','mapped_racecmb','STATECENSUS'], as_index=False)['WTSUPP'].sum()\n",
    "population_by_cell.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then merge the populations into the cell data, by joining on the combination of sex, race, and state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_pop = all_cells_with_trace.merge(population_by_cell, \n",
    "                                                left_on=['sex','racecmb','state'], \n",
    "                                                right_on=['SEX','mapped_racecmb','STATECENSUS'],\n",
    "                                                validate='1:1')\n",
    "all_cells_with_pop.drop(columns=['SEX','mapped_racecmb','STATECENSUS'], inplace=True)\n",
    "all_cells_with_pop.rename(columns={'WTSUPP':'population'}, inplace=True)\n",
    "all_cells_with_pop[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the probability of voting for Trump and the population from each cell, I'll add columns with calculated number of votes for Clinton and Trump.\n",
    "\n",
    "I'll do this in a function so that I can reuse the same code below when I add vote counts from other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_vote_columns(df, population_col, prob_col, vote_col_prefix):\n",
    "    \"\"\"\n",
    "    Add columns that contain the number of Clinton and Trump votes to the passed data frame.\n",
    "    \n",
    "    df: dataframe with population and probability data, and to which the new columns are \n",
    "    to be added\n",
    "    population_col: name of the column in df that holds the population\n",
    "    prob_col: name of the column in df that holds the probability of voting for Trump\n",
    "    vote_col_prefix: prefix to be added to the new vote columns\n",
    "    \"\"\"\n",
    "    df_new = df.copy()\n",
    "    df_new[f\"{vote_col_prefix}_clinton\"] = np.round(df_new[population_col] * (1 - df_new[prob_col])).astype(int)\n",
    "    df_new[f\"{vote_col_prefix}_trump\"] = np.round(df_new[population_col] * df_new[prob_col]).astype(int)\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_results = add_vote_columns(all_cells_with_pop, 'population', 'trump_prob', 'votes')\n",
    "all_cells_with_results[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate MRP prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have everything I need - votes for Clinton and Trump, per cell - to calculate the final prediction with data from all cells. \n",
    "\n",
    "I'll define a function that calculates the totals and proportions, and that persists these results in a row that I'll add to a dataframe as I go along, building up a single results dataframe that summarizes my results across all of the models I'll try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_counts_and_proportions(label, clinton_count, trump_count, verbose=True):\n",
    "    \"\"\"\n",
    "    Return results for a single model as a dataframe row.\n",
    "    \n",
    "    label: index/label value for the row, should describe the model\n",
    "    clinton_count: total votes for Clinton\n",
    "    trump_count: total votes for Trump\n",
    "    verbose: if True, print results in addition to returning the row\n",
    "    \"\"\"\n",
    "    all_rows_count = clinton_count + trump_count\n",
    "    clinton_prop = clinton_count / all_rows_count\n",
    "    trump_prop = trump_count / all_rows_count\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Total  \\t{all_rows_count:,}\")\n",
    "        print(f\"Clinton\\t{clinton_count:,} ({clinton_prop:.1%})\")\n",
    "        print(f\"Trump  \\t{trump_count:,} ({trump_prop:.1%})\")\n",
    "    \n",
    "    return pd.DataFrame.from_records(data=[(clinton_count, clinton_prop, trump_count, trump_prop, all_rows_count)], \n",
    "                                     index=[label],\n",
    "                                     columns=['Clinton count','Clinton proportion','Trump count','Trump proportion','Total count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then I'll start my results dataframe using the model I've built up to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_comparison = get_counts_and_proportions(\"Bayesian MRP\", \n",
    "                                               all_cells_with_results['votes_clinton'].sum(),\n",
    "                                               all_cells_with_results['votes_trump'].sum())\n",
    "\n",
    "result_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate prediction from poll using poll weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poll data itself contains weighting information. This information, a result of sophisticated weighting performed by the good people at Pew, could be used to make the poll data representative of people likely to vote. The Bayesian MRP model above completely ignores the weighting information that comes with the poll data itself... that is, it uses the raw poll data and doesn't up front weight the data. Put differently, without using the weighting data, I think the poll data is unrepresentative.\n",
    "\n",
    "Ideally the prediction I get from my Bayesian MRP model, based on just the unrepresentative data from the poll, but adjusted using MRP, would be close to the prediction baeed on Pew's weighting. To compare, then, this section calculates the poll's predictions - once after weighting and once without weighting - and adds these predictions to the results dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_only.groupby(['q10horseGP'])['weight'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_comparison = pd.concat([result_comparison, get_counts_and_proportions(\"Pew Research, weighted\",\n",
    "    round(d_only[d_only['q10horseGP'] == 'Clinton/lean Clinton']['weight'].sum()),\n",
    "    round(d_only[d_only['q10horseGP'] == 'Trump/lean Trump']['weight'].sum()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if I don't use the weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_comparison = pd.concat([result_comparison, get_counts_and_proportions(\"Pew Research, unweighted\",\n",
    "    len(d_only[d_only['q10horseGP'] == 'Clinton/lean Clinton']),\n",
    "    len(d_only[d_only['q10horseGP'] == 'Trump/lean Trump']))])\n",
    "\n",
    "result_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I discuss these results in the Findings section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does adjusting for likelihood to vote change the MRP predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of ways I can improve the model I've already defined and hopefully improve its prediction; I'll discuss many of these options below in the Discussion section. \n",
    "\n",
    "I did want to try one particular potential improvement that tries to answer a primary concern: does the fact that I'm not considering whether a person is actually going to vote hurt my results? For example, I don't want to include, say, a heavy contribution from a cell that's heavily pro-Clinton or pro-Trump, IF the people in that cell aren't likely to vote, or if they're too young to vote, etc.\n",
    "\n",
    "As a first cut at estimating the degree to which people in different cells vote, I'll use an additional CPS data set from the US Census and IPUMS at the University of Minnesota. Like with the previous data sets, this data is documented in more detail in the [README](README.md). The vote data, from the November 2016 monthly data set, contains a row per person surveyed, with the person's sex, race/ethnicity, state, and whether the person voted in the most recent election - this voted data is only available in the \"monthly\" data sets, and is not in the ASEC 2016 data set I used previously. Each row also contains a weight column, now called WTFINL, that shows the degree to which that person's observation should be weighted so that the end result is representative of the US population. \n",
    "\n",
    "(This data is similar to but not the same as the CPS population data used previously - they come from different IPUMS/CPS samples. As described in the README, the vote data comes from the November 2016 \"monthly\" data set and the population data comes from the ASEC 2016 data set. I think I could potentially get all of the data I need for both population and voting behavior from the monthly data, but I only first pulled the monthly data to get the voted data and didn't want to spend the time to go back and change and verify the population calculations, at least for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_voting = pd.read_csv('cps_votes.csv')\n",
    "d_voting.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_voting[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to remap the CPS race/ethnicity values to match the Pew values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_voting['mapped_racecmb'] = d_voting['RACE'].map(map_cps_race_to_pew_racecmb)\n",
    "d_voting['mapped_racecmb'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have 510 cells, and I should have 510 counts of voters. Do I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_voting_pop_by_cell = d_voting.groupby(['SEX','mapped_racecmb','STATEFIP'], as_index=False)['WTFINL'].sum()\n",
    "d_voting_pop_by_cell.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm... nope - I have 508 when I should have 510. \n",
    "\n",
    "Which states don't have all one row for each cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(d_voting_pop_by_cell['STATEFIP'].unique())[d_voting_pop_by_cell.groupby('STATEFIP').size() < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_voting_pop_by_cell[d_voting_pop_by_cell['STATEFIP'] == 'Maine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_voting_pop_by_cell[d_voting_pop_by_cell['STATEFIP'] == 'Vermont']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out that Maine is missing females of 'Or some other race' and Vermont is missing males of 'Or some other race'. I'll handle this in the function below that calculates the proportion that voted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_voted_pop_by_cell = None\n",
    "d_didnotvote_pop_by_cell = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_voted_proportion(g):\n",
    "    \"\"\"\n",
    "    Return the proportion that voted for the passed group, handling cases where there are no\n",
    "    voted and/or not voted rows; meant to be called from a groupby.\n",
    "    \"\"\"\n",
    "    voted_count = g[g['VOTED'] == 'Voted']['WTFINL'].sum()\n",
    "    if np.isnan(voted_count): # if there are no vote rows, then I had zero (don't think there's a way to do this via a built-in function)\n",
    "        voted_count = 0\n",
    "    \n",
    "    didnotvote_count = g[g['VOTED'] == 'Did not vote']['WTFINL'].sum()\n",
    "    if np.isnan(didnotvote_count): \n",
    "        didnotvote_count = 0\n",
    "\n",
    "    total_count = voted_count + didnotvote_count\n",
    "    \n",
    "    # I can only return a proportion when I have at least some rows; otherwise I return NaN\n",
    "    if total_count != 0:\n",
    "        return voted_count / (voted_count + didnotvote_count)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the above function, calculate the proportion that voted for each cell, and then add this proportion to the cell data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to use reset_index instead of as_index=False because the latter isn't working w/ .apply\n",
    "d_voted_prop = d_voting.groupby(['SEX','mapped_racecmb','STATEFIP']).apply(get_voted_proportion).reset_index()\n",
    "d_voted_prop.rename(columns={0:'voted_prop','SEX':'sex','mapped_racecmb':'racecmb','STATEFIP':'state'}, inplace=True)\n",
    "d_voted_prop[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_results_and_voted_prop = all_cells_with_results.merge(d_voted_prop, \n",
    "                on=['sex','racecmb','state'], how='left')\n",
    "all_cells_with_results_and_voted_prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_results_and_voted_prop[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute/guess at some proportions where I don't have data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The November 2016 monthly CPS data doesn't have voted data for every single one of the 510 cells. For two - noted above - there's no data at all/no rows at all for a particular combination, and for more than two there are at least some cases where there are no rows that have values of 'voted' or 'did not vote'. In either case, I have a NaN, since I can't say anything at all about that cell. (There are also some cells where all of the rows are either vote or did not vote, and I've - for better or worse - already marked these as 100% or 0%, respectively.)\n",
    "\n",
    "For ease of implementation, I'll start by just setting these values to the average voted proportion (overall - I could do it from common cells, but won't bother since the number of affected votes is small)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_count = d_voting[d_voting['VOTED'] == 'Voted']['WTFINL'].sum()\n",
    "did_not_vote_count = d_voting[d_voting['VOTED'] == 'Did not vote']['WTFINL'].sum()\n",
    "overall_prop_voted = voted_count / (voted_count + did_not_vote_count)\n",
    "overall_prop_voted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cells_with_results_and_voted_prop['voted_prop'].fillna(overall_prop_voted, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I shouldn't have any rows with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_results_and_voted_prop[all_cells_with_results_and_voted_prop['voted_prop'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add counts for population that votes, and for Clinton and Trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I can calculate first a new population count for each cell, by multiplying the overall population by an estimate of the proportion that vote, and then split up this new count into Clinton and Trump votes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_results_and_adj_voted_data = all_cells_with_results_and_voted_prop.copy()\n",
    "all_cells_with_results_and_adj_voted_data['est_population_voted'] = all_cells_with_results_and_adj_voted_data['population'] * \\\n",
    "            all_cells_with_results_and_adj_voted_data['voted_prop']\n",
    "all_cells_with_results_and_adj_voted_data = add_vote_columns(all_cells_with_results_and_adj_voted_data, \n",
    "            'est_population_voted', 'trump_prob', 'votes_adj')\n",
    "\n",
    "all_cells_with_results_and_adj_voted_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the prediction based on counts adjusted for likelihood to vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then add the results using the likelihood of voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_comparison = pd.concat([result_comparison, get_counts_and_proportions(\"Bayesian MRP (adjusted for likelihood of voting)\",\n",
    "    all_cells_with_results_and_adj_voted_data['votes_adj_clinton'].sum(),\n",
    "    all_cells_with_results_and_adj_voted_data['votes_adj_trump'].sum())])\n",
    "\n",
    "result_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proportion is dismayingly close to the original prediction - here 0.5685 vs 0.5678, even though the number of votes is much smaller and, from a quick review, there are cells that have different proportions of people that voted and could affect the overall numbers. \n",
    "\n",
    "However, this is evidence that the difference between my original prediction and the Pew prediction isn't solely due to the fact that I originally did not account for likelihood to vote.\n",
    "\n",
    "Also, some or all of the difference could be that I should adjust for the likelihood to vote in some other fashion. For example, the Xbox paper introduced above appears to adjust for likelihood to vote by creating an additional Bayesian model to predict whether someone will vote for one of the two primary candidates, and then feeds the output of this model into another model that estimates the proportion voting for one candidate or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the prediction if I use a simple logistic regression for the proportions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of post-stratification generally is estimating the proportion for each cell. Above I've done this with a Bayesian multi-level regression model. While not complicated, as far as Bayesian inference models go, it's certainly more complicated than something like an ordinary least squares logistic regression model, and certainly takes a _lot_ more computing power to produce. \n",
    "\n",
    "For the sake of comparison, what kind of performance do I get if I do just use a simple OLS logistic regression model?\n",
    "\n",
    "I can do this using the same set of y_obs results and the d_only_dummies dataframe of indicator variables, and Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(d_only_dummies.values, y_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then calculate and use the proportions and calculated vote counts based on this model to the set of all cells data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_results_and_adj_voted_data_and_lr_prob = all_cells_with_results_and_adj_voted_data.copy()\n",
    "\n",
    "# calculate estimated proportion, again using matrix multiplication to do it one line and quickly\n",
    "all_cells_with_results_and_adj_voted_data_and_lr_prob['lr_prob'] = \\\n",
    "    standard_logistic(all_cells_dummies.dot(lr.coef_.T) + lr.intercept_)\n",
    "    \n",
    "all_cells_with_results_and_adj_voted_data_and_lr = add_vote_columns(all_cells_with_results_and_adj_voted_data_and_lr_prob, \n",
    "                                                                    'population', 'lr_prob', 'lr_votes')\n",
    "    \n",
    "all_cells_with_results_and_adj_voted_data_and_lr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_with_results_and_adj_voted_data_and_lr[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And update the results dataframe with the overall prediction based on the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_comparison = pd.concat([result_comparison, get_counts_and_proportions(\"Logistic regression (OLS)\",\n",
    "    all_cells_with_results_and_adj_voted_data_and_lr['lr_votes_clinton'].sum(),\n",
    "    all_cells_with_results_and_adj_voted_data_and_lr['lr_votes_trump'].sum())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, I'm curious if the probabilities estimated by the Bayesian multi-level logistic regression model pass the sniff test... do they make sense?\n",
    "\n",
    "To check this, I'll get a table that shows all probabilities, by state and sex/race, and then draw it as a heatmap. I'll also shorten a few of the longer state names so they're more legible when rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_probs_by_sex_and_race = all_cells.pivot_table(columns=['sex','racecmb'],index='state',values='trump_prob').T\n",
    "trump_probs_by_sex_and_race.rename(columns={'District of Columbia':'D.C.',\n",
    "                                            'Massachusetts':'Mass.',\n",
    "                                            'New Hampshire':'New Hamp.',\n",
    "                                            'North Carolina':'N. Carolina',\n",
    "                                            'South Carolina':'S. Carolina',\n",
    "                                            'North Dakota':'N. Dakota'}, inplace=True)\n",
    "trump_probs_by_sex_and_race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the data as a horizontally-oriented heat map. \n",
    "\n",
    "At least visually, it does look like the model generates probabilities that make sense. For example, relatively liberal coastal states tend Clinton while states in the interior and in the South, at least, prefer Trump at higher rates. Males prefer Trump more than females, and there are significant differences by race/ethnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "ax = sns.heatmap(trump_probs_by_sex_and_race, cmap='Blues')\n",
    "\n",
    "ax.set_title('Estimated probability of Trump vote, by sex, race/ethnicity, and state')\n",
    "ax.set_xlabel('State')\n",
    "ax.set_ylabel('Sex and race/ethnicity')\n",
    "\n",
    "# rotate state labels so they're at least a bit easier to read\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want a vertically-oriented heatmap that I can more easily use in a presentation, and I'll generate that here. For this one I'll shorten some of the race/ethnicity values so they fit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shorten_racecmb_values = {'Asian or Asian-American':'Asian',\n",
    "                          'Black or African-American':'Black',\n",
    "                          'Mixed Race':'Mixed',\n",
    "                          'Or some other race':'Other',\n",
    "                          'White':'White'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_probs_by_state = all_cells.pivot_table(columns=['sex','racecmb'],index='state',values='trump_prob')\n",
    "# shorten racecmb labels for display, hack per https://stackoverflow.com/questions/32892751/set-level-values-in-multiindex\n",
    "trump_probs_by_state.columns = trump_probs_by_state.columns.set_levels(trump_probs_by_state.columns.levels[1].map(shorten_racecmb_values.get), \"racecmb\")\n",
    "trump_probs_by_state.columns = [', '.join(col).strip() for col in trump_probs_by_state.columns.values]\n",
    "\n",
    "trump_probs_by_state[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,11))\n",
    "ax = sns.heatmap(trump_probs_by_state, cmap='Blues')\n",
    "\n",
    "ax.set_title('Estimated probability of Trump vote, by state, sex, and race/ethnicity')\n",
    "ax.set_ylabel('State')\n",
    "ax.set_xlabel('Sex and race/ethnicity')\n",
    "\n",
    "# rotate and shift x axis labels by a bit for aesthetic reasons\n",
    "for i, tick in enumerate(ax.get_xticklabels()):\n",
    "    tick.set_rotation(20)\n",
    "    tick.set_ha('right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to view, all up, the results per model, and compare the performance to the weighting that's a part of the Pew poll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_comparison[['Clinton proportion','Trump proportion']].applymap('{:.1%}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the estimate I calculated using one of the Bayesian MRP models would be close to the estimate from the Pew poll. This isn't the case: all of the models I tried provide estimates that have Clinton favored by about an additional three percentage points over the Pew poll. My first guess at why this is happening is that I'm simply not stratifying on enough of the important variables to fully adjust the unrepresentative sample and make it representative. Based on the documentation provided with the Pew data, the Pew results are weighted by eight separate features: \"sex, age, education, race, Hispanic origin, region (U.S. Census definitions), population density, and telephone usage\". Of these I currently only stratify based on two - sex and race. \n",
    "\n",
    "It's also interesting that the estimates from the very simple OLS logistic regression model are so close to the estimates from the Bayesian models. One of the benefits of a Bayesian hierarchical model is that it shares data between similar features, and this can be especially useful in cases where there is a little or no data for particular features. This property is known as 'shrinkage' because it shrinks estimates toward the value common across the data. I would have expected that this would be helpful in this project because the poll data is minimal, for example, for many states. However, the difference in the Clinton and Trump proportions are small enough, and close enough to a coin flip of 50%, that the shrinkage isn't easy to see. (It's not that shrinkage isn't working entirely - in the [ProjectResearch](ProjectResearch.ipynb) notebook I tested some artifical data with 1/3 and 2/3 proportions and reliably saw shrinkage for cells with little data to the 1/3 and 2/3 values.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save generated raw results/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I'll output the detailed per-cell data to a file for easier possible future use. The fields are described in detail in a table in the [README](README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cells_with_results_and_adj_voted_data_and_lr.to_csv('mrp_cells.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based at least on what I've found in this project, post-stratifying an unrepresentative sample using a Bayesian multi-level regression model shows promise and should be possible, but it's not something that I at least was able to do in a relatively short time. Nonetheless, this notebook and the code in this repository at least provide a full example - from data to results - that shows how to use MRP with election data, and does so using \"full\" Bayesian inference with MCMC (as opposed to a simpler approach that, for example, just provides maximum likelihood estimates).\n",
    "\n",
    "There are a number of things that could be done to learn more - non-exhaustively:\n",
    "\n",
    "- As noted previously, I'd like to see if using additional fields improves the performance. The data from the ASEC 2016 data set includes many fields that could help, including age, 'density' (population density of the state), region (Census region), income, and highest level of school/highest degree. \n",
    "- Right now the handling of the propensity to vote and of voters with preferences besides Clinton and Trump might be insufficient. For example, the Xbox paper describes using two models: one that predicts whether a person is going to vote for the main candidates and then one that predicts the preference for those voters.\n",
    "- The full Bayesian approach provides a lot of additional data on the variability/uncertainty in things like probabilities. For example, it shows that the uncertainty can vary substantially by cell. It would be interesting to try to incorporate estimates of variability into the results.\n",
    "- The diagnostics for my MCMC sample could probably be better. For example, the mixing for many of the parameters isn't great. Can I fix this via changing the model? To what degree, really, is this a problem with this project?\n",
    "- In terms of the model, do I need an intercept? Does removing the intercept affect the performance? Does it help with sampling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project references:\n",
    "- [README](README.md).\n",
    "- [ProjectResearch](ProjectResearch.ipynb) notebook.\n",
    "\n",
    "External references:\n",
    "- [Bayesian Analysis with Python](https://www.amazon.com/Bayesian-Analysis-Python-Osvaldo-Martin/dp/1785883801/ref=tmm_pap_swatch_0?_encoding=UTF8&qid=1512752450&sr=8-1); Martin.\n",
    "- [Deep Interactions with MRP: Election Turnout and Voting Patterns Among Small Electoral Subgroups](http://www.stat.columbia.edu/~gelman/research/published/misterp.pdf); Ghitza, Gelman.\n",
    "- [Doing Bayesian Data Analysis, Second Edition: A Tutorial with R, JAGS, and Stan](https://www.amazon.com/Doing-Bayesian-Data-Analysis-Second/dp/0124058884/ref=sr_1_1?ie=UTF8&qid=1512752434&sr=8-1&keywords=kruschke); Kruschke. \n",
    "- [Estimating State Public Opinion With Multi-Level Regression and Poststratification using R](http://www.princeton.edu/~jkastell/MRP_primer/mrp_primer.pdf); Kastellec, Lax, Phillips.\n",
    "- [Forecasting elections with non-representative polls](http://www.stat.columbia.edu/~gelman/research/published/forecasting-with-nonrepresentative-polls.pdf); Wang, Rothschild, Goel, Gelman.\n",
    "- [How One 19-Year-Old Illinois Man Is Distorting National Polling Averages](https://www.nytimes.com/2016/10/13/upshot/how-one-19-year-old-illinois-man-is-distorting-national-polling-averages.html); Cohn.\n",
    "- [Mister P can solve problems with survey weighting](http://andrewgelman.com/2016/10/12/31398/); Gelman.\n",
    "- [Mister P: Whatâ€™s its secret sauce?](http://andrewgelman.com/2013/10/09/mister-p-whats-its-secret-sauce/); Gelman.\n",
    "- [Post-stratification](https://onlinecourses.science.psu.edu/stat506/node/29); Wikipedia.\n",
    "- [Propensity score matching](https://en.wikipedia.org/wiki/Propensity_score_matching); Wikipedia.\n",
    "- [PyMC3](https://github.com/pymc-devs/pymc3) project site.\n",
    "- [Statistical Rethinking: A Bayesian Course with Examples in R and Stan](https://www.amazon.com/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/1482253445/ref=sr_1_1?ie=UTF8&qid=1512752416&sr=8-1&keywords=richard+mcelreath); McElreath.\n",
    "- [We Gave Four Good Pollsters the Same Raw Data. They Had Four Different Results](https://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html); Cohn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Ideally I'd use Markdown reference-style links, as described in the [Daring Fireball Markdown docs](https://daringfireball.net/projects/markdown/syntax#link), but it looks like they're not supported by Jupyter Notebook at least, so I'll just use inline-style links in the body of the notebook and here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
