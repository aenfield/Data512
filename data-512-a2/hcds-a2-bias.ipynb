{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfield, Andrew - DATA 512, A2: Bias in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD UPDATE\n",
    "\n",
    "The assignment is at https://wiki.communitydata.cc/HCDS_(Fall_2017)/Assignments#A2:_Bias_in_data.\n",
    "\n",
    "TBD remove\n",
    "\n",
    "This notebook pulls, prepares, and analyzes data about the amount of monthly English Wikipedia traffic from January 1, 2008 through September 30, 2017. For more information about the work and data, refer to the [README](Readme.md).\n",
    "\n",
    "A few notes:\n",
    "- Normally I'd prefer to keep the explanation and background that's in the README here in the notebook, so everything's in a single file, but I've split it up this time as that's what the assignment requested. I won't copy/paste because keeping duplicate content in sync is horrible.\n",
    "- Real reproducibility needs tests for the code. A lot of my implementation below is in functions. I'd normally put these functions in at least one separate file that I import into this notebook, and I'd have tests in an additional file. For this assignment I'll just keep everything in this file, for simplicity, even though it means I can't test the code the way I normally would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** I want a data section, where i note that there are issues, in one place. These include:\n",
    "\n",
    "- articles that aren't actually a single politician, like 'History of monarchy in Canada\tCanada\t806849461\n",
    "'\n",
    "- follow on to above bullet that i deleted the Template: articles and why \n",
    "- something about Oliver's comments about multiple levels of hierarchy\n",
    "- incomplete mapping of countries even after Oliver's and my follow on remapping\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prereqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code requires the libraries as described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve, load data\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# prepare and analyze data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.axes_grid.anchored_artists import AnchoredText # for addtl annotations in charts\n",
    "#from matplotlib.ticker import FuncFormatter # for custom axis labels\n",
    "from IPython.core.pylabtools import figsize\n",
    "import seaborn as sns # for formatting\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "figsize(14,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and do basic data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD UPDATE\n",
    "\n",
    "This section loads the data from the two APIs described in the README, producing five separate .json files, one for each API and access combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47197, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia = pd.read_csv('page_data.csv')\n",
    "d_wikipedia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Template:ZambiaProvincialMinisters</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>235107991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Template:Zimbabwe-politician-stub</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>391862046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 page   country     rev_id\n",
       "0  Template:ZambiaProvincialMinisters    Zambia  235107991\n",
       "1                      Bir I of Kanem      Chad  355319463\n",
       "2   Template:Zimbabwe-politician-stub  Zimbabwe  391862046"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, before we use the data to pull scores, we'll filter out the 'Template' entries.\n",
    "\n",
    "**TODO** Note that while Oliver said he'd keep these entries, as they're evidence of coverage/activity, I'm going to drop them. I agree w/ Oliver, but I'm not sure that they're the same kind of coverage - are these apples to the actual per-politician page oranges? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46701, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia.drop(d_wikipedia[d_wikipedia['page'].str.startswith('Template:')].index, inplace=True)\n",
    "d_wikipedia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Information Minister of the Palestinian Nation...</td>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>393276188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yos Por</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>393822005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 page                country  \\\n",
       "1                                      Bir I of Kanem                   Chad   \n",
       "10  Information Minister of the Palestinian Nation...  Palestinian Territory   \n",
       "12                                            Yos Por               Cambodia   \n",
       "\n",
       "       rev_id  \n",
       "1   355319463  \n",
       "10  393276188  \n",
       "12  393822005  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_population = pd.read_csv('Population Mid-2015.csv', skiprows=2, thousands=',')\n",
    "d_population.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "France            1681\n",
       "Australia         1561\n",
       "China             1133\n",
       "United States     1092\n",
       "Mexico            1077\n",
       "Pakistan          1040\n",
       "India              985\n",
       "Russia             877\n",
       "Spain              876\n",
       "United Kingdom     863\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia.groupby(['country']).size().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>TimeFrame</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Data</th>\n",
       "      <th>Footnotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>32247000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>2892000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Country</td>\n",
       "      <td>Mid-2015</td>\n",
       "      <td>Number</td>\n",
       "      <td>39948000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location Location Type TimeFrame Data Type      Data  Footnotes\n",
       "0  Afghanistan       Country  Mid-2015    Number  32247000        NaN\n",
       "1      Albania       Country  Mid-2015    Number   2892000        NaN\n",
       "2      Algeria       Country  Mid-2015    Number  39948000        NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_population[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull article scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs: https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context_revid_model and https://ores.wikimedia.org/v3/#!/scoring/get_v3_scores_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when I try the multiple rev ID API with a bunch of valid IDs and one that's a text string, then it gives me a 500 and no data at all. However when I try with a bunch of valid IDs and an ID that's not valid - like -1 - then I get valid/good data for the valid IDs and output like the following. This seems good: I'll go ahead and try just pulling batches of IDs w/o further error handling.\n",
    "\n",
    "    \"-1\": {\n",
    "        \"wp10\": {\n",
    "          \"error\": {\n",
    "            \"message\": \"RevisionNotFound: Could not find revision ({revision}:-1)\",\n",
    "            \"type\": \"RevisionNotFound\"\n",
    "          }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_agent = 'https://github.com/aenfield'\n",
    "\n",
    "def get_multiple_full_ores_score_json(rev_ids):\n",
    "    \"\"\"TBD referring to ..., with rev_ids as a list\"\"\"\n",
    "    endpoint = 'https://ores.wikimedia.org/v3/scores/enwiki?models=wp10&revids={rev_ids_delimited}'\n",
    "\n",
    "    rev_ids_delimited = '|'.join([str(i) for i in rev_ids])\n",
    "\n",
    "    params = { 'rev_ids_delimited' : rev_ids_delimited }\n",
    "\n",
    "    api_call = requests.get(endpoint.format(**params), headers = {'User-Agent':'{}'.format(user_agent)})\n",
    "    return api_call.json()\n",
    "    \n",
    "def get_ores_prediction_from_score_json(score_json, rev_id):\n",
    "    \"\"\"Return the most likely article type, per ORES. Assumes a JSON dict from Ores. \"\"\"\n",
    "    #print(rev_id)\n",
    "    try:\n",
    "        return score_json['enwiki']['scores'][str(rev_id)]['wp10']['score']['prediction']\n",
    "    except KeyError as err:\n",
    "        return f\"KeyError: {err}.\"\n",
    "            \n",
    "def chunker(seq, size):\n",
    "    \"\"\"Get a generator that returns chunks of size 'size' of the sequence in 'seq'.\n",
    "    \n",
    "    From: https://stackoverflow.com/questions/434287/what-is-the-most-pythonic-way-to-iterate-over-a-list-in-chunks\n",
    "    \"\"\"\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "def get_article_scores_data(rev_ids, force=False, verbose=False):\n",
    "    \"\"\"TBD update Download and save results from the specified API to a local file, by default only if local file doesn't exist.\n",
    "    TBD call with d_wikipedia['last_edit'].values for 'rev_ids'\n",
    "    \n",
    "    apiname - 'pagecounts' or 'pageviews'\n",
    "    params - a dict containing 'access', 'start', and 'end' keys; use get_param_dict_from_params\n",
    "    user_agent - an identifier for the user making the request; can be a GitHub user URL or general email address\n",
    "    force - download data and overwrite local file, even if file already exists; default is False\n",
    "    verbose - print diagnostic data; default is false\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = 'article_scores.csv'\n",
    "\n",
    "    if (not os.path.exists(filename)) | (force == True):\n",
    "        # download and save the data locally\n",
    "        if verbose: print(\"Local file doesn't exist or download was forced. Downloading...\")\n",
    "        with open(filename, 'w') as output_file:\n",
    "            writer = csv.writer(output_file, delimiter=',')\n",
    "            writer.writerow(['RevisionId','Score'])\n",
    "\n",
    "            progress_frequency = 25\n",
    "            count_of_rev_ids_in_chunk = 140\n",
    "            rev_ids_in_chunks = [x for x in chunker(rev_ids, count_of_rev_ids_in_chunk)]\n",
    "\n",
    "            #rev_ids_in_chunks = rev_ids_in_chunks[300:]\n",
    "            \n",
    "            for chunk_index, chunk_of_rev_ids in enumerate(rev_ids_in_chunks):\n",
    "                if (chunk_index % progress_frequency == 0): print(f\"Retrieving chunk with index {chunk_index}.\")\n",
    "\n",
    "                scores_json = get_multiple_full_ores_score_json(chunk_of_rev_ids)\n",
    "                #print(scores_json)\n",
    "                for rev_id in chunk_of_rev_ids:\n",
    "                    writer.writerow([rev_id, get_ores_prediction_from_score_json(scores_json, rev_id)])\n",
    "\n",
    "            if verbose: print(f\"Retrieved {chunk_index + 1} chunks and saved to {filename}. Done.\")        \n",
    "    else:\n",
    "        if verbose: print(\"Local file exists already.\")\n",
    "                  \n",
    "    # now open and return dataframe\n",
    "    return pd.read_csv(filename, index_col='RevisionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46701, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_scores = get_article_scores_data(d_wikipedia['rev_id'].values)\n",
    "d_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some articles may have been deleted since the page_data list was created. How many of these occurred? And then we'll filter them out, since we can't get a score for something that doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_scores[d_scores['Score'].str.startswith('KeyError')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevisionId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>807367030</th>\n",
       "      <td>KeyError: 'score'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807367166</th>\n",
       "      <td>KeyError: 'score'.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "RevisionId                    \n",
       "807367030   KeyError: 'score'.\n",
       "807367166   KeyError: 'score'."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_scores[d_scores['Score'].str.startswith('KeyError')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46699, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_scores.drop(d_scores[d_scores['Score'].str.startswith('KeyError')].index, inplace=True)\n",
    "d_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_scores[d_scores['Score'].str.startswith('KeyError')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now join to pull in the score data.\n",
    "\n",
    "If there are rows with no score data, the page data will have nulls for the new score column. I'll filter these rows out below when I clean up rows with incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46701, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia_with_scores = pd.merge(left=d_wikipedia, right=d_scores, left_on='rev_id', right_index=True, how='left')\n",
    "d_wikipedia_with_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Information Minister of the Palestinian Nation...</td>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>393276188</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yos Por</td>\n",
       "      <td>Cambodia</td>\n",
       "      <td>393822005</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 page                country  \\\n",
       "1                                      Bir I of Kanem                   Chad   \n",
       "10  Information Minister of the Palestinian Nation...  Palestinian Territory   \n",
       "12                                            Yos Por               Cambodia   \n",
       "\n",
       "       rev_id Score  \n",
       "1   355319463  Stub  \n",
       "10  393276188  Stub  \n",
       "12  393822005  Stub  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia_with_scores[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stub     23707\n",
       "Start    15341\n",
       "C         5764\n",
       "GA         872\n",
       "B          735\n",
       "FA         280\n",
       "NaN          2\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia_with_scores['Score'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46701, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_wikipedia.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_wikipedia_with_scores) - len(d_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46699, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46701 entries, 1 to 47196\n",
      "Data columns (total 4 columns):\n",
      "page       46701 non-null object\n",
      "country    46701 non-null object\n",
      "rev_id     46701 non-null int64\n",
      "Score      46699 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "d_wikipedia_with_scores.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# d_wikipedia_with_scores.to_excel('eyeball.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46701"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_wikipedia_with_scores['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46701"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_wikipedia['rev_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46699"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d_scores.index.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally the page_data data set had duplicates. It looks like that's no longer the case, but I'll check for them here to confirm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [page, country, rev_id, Score]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupes = d_wikipedia_with_scores[d_wikipedia_with_scores.duplicated(subset='rev_id', keep=False)].sort_values(['rev_id','page'])\n",
    "dupes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join to pull in the population data. For now we'll do an outer join so we can see the country values that don't exist on _both_ sides of the join. This isn't needed for the assignment because it says to just remove all rows that don't have matching data. But, I'm curious and I also want to at least see if there are places where I could do any further matching to expand/improve the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46724, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all = pd.merge(left=d_wikipedia_with_scores, right=d_population[['Location','Data']],\n",
    "                 how='outer', left_on='country', right_on='Location')\n",
    "d_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Chad</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abdullah II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>498683267.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Chad</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salmama II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>565745353.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Chad</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   page country       rev_id Score Location        Data\n",
       "0        Bir I of Kanem    Chad  355319463.0  Stub     Chad  13707000.0\n",
       "1  Abdullah II of Kanem    Chad  498683267.0  Stub     Chad  13707000.0\n",
       "2   Salmama II of Kanem    Chad  565745353.0  Stub     Chad  13707000.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show the countries that exist on each side but not on the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, countries that exist in the Wikipedia data but not in the population data, w/ the number of rows - here, the number of pages - for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hondura                             187\n",
       "Salvadoran                          116\n",
       "South Korean                         96\n",
       "Cape Colony                          81\n",
       "Samoan                               76\n",
       "Rhodesian                            75\n",
       "Faroese                              74\n",
       "Ivorian                              73\n",
       "Cook Island                          67\n",
       "Jersey                               61\n",
       "Saint Lucian                         47\n",
       "Pitcairn Islands                     43\n",
       "Chechen                              38\n",
       "East Timorese                        36\n",
       "Saint Kitts and Nevis                30\n",
       "Montserratian                        27\n",
       "Guernsey                             25\n",
       "Omani                                24\n",
       "Carniolan                            22\n",
       "Niuean                               22\n",
       "Palauan                              21\n",
       "Saint Vincent and the Grenadines     21\n",
       "South Ossetian                       18\n",
       "Tokelauan                            17\n",
       "Abkhazia                             16\n",
       "South African Republic               15\n",
       "Greenlandic                          13\n",
       "Ossetian                              9\n",
       "Dagestani                             7\n",
       "Incan                                 7\n",
       "Somaliland                            4\n",
       "Rojava                                2\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all[d_all['Location'].isnull()]['country'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the countries that exist in the population data but not in the Wikipedia data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hong Kong, SAR                  1\n",
       "New Caledonia                   1\n",
       "St. Vincent & the Grenadines    1\n",
       "Samoa                           1\n",
       "Macao, SAR                      1\n",
       "St. Kitts-Nevis                 1\n",
       "El Salvador                     1\n",
       "Puerto Rico                     1\n",
       "Guam                            1\n",
       "Palau                           1\n",
       "Channel Islands                 1\n",
       "Western Sahara                  1\n",
       "Mayotte                         1\n",
       "French Polynesia                1\n",
       "Cote d'Ivoire                   1\n",
       "Reunion                         1\n",
       "Oman                            1\n",
       "St. Lucia                       1\n",
       "Honduras                        1\n",
       "Brunei                          1\n",
       "Georgia                         1\n",
       "Timor-Leste                     1\n",
       "Curacao                         1\n",
       "Name: Location, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all[d_all['country'].isnull()]['Location'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#d_population.to_excel('population.xlsx')\n",
    "#d_wikipedia_with_scores['country'].value_counts(dropna=False).reset_index().to_excel('page countries.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on eyeballing of the most common Wikipedia countries for which we have no population data - I included all countries with 70 or more pages - I came up with the following mapping that I'll use to update the country field in the Wikipedia data, so we _will_ have population data. This is probably clearly better for some countries that map directly - for example updating 'South Korean' to 'Korea, South'. It's fuzzier for at least some others, including for example Wikipedia countries that aren't around anymore in the way they were when the leader was in power, like Cape Colony and Rhodesia. Good enough for now though.\n",
    "\n",
    "In addition, there are clearly others that I could also map - for example, 'Saint Vincent and the Grenadines' in the Wikipedia data could be changed to 'St. Vincent & the Grenadines', but all of the ones I didn't manually map have fewer than 70 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikipedia_country_to_population_map = {'Burkinab√©':'Burkina Faso',\n",
    "                                       'Ivorian':\"Cote d'Ivoire\",\n",
    "                                       'Faroese':'Denmark',\n",
    "                                       'Salvadoran':'El Salvador',\n",
    "                                       'Hondura':'Honduras',\n",
    "                                       'South Korean':'Korea, South',\n",
    "                                       'Samoan':'Samoa',\n",
    "                                       'Cape Colony':'United Kingdom',\n",
    "                                       'Rhodesian':'Zimbabwe'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_wikipedia_with_scores['country'].update(d_wikipedia_with_scores['country'].map(wikipedia_country_to_population_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we need to re-merge the population data.\n",
    "\n",
    "**TODO** This is duplication. DRY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46720, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all = pd.merge(left=d_wikipedia_with_scores, right=d_population[['Location','Data']],\n",
    "                 how='outer', left_on='country', right_on='Location')\n",
    "d_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cook Island                         67\n",
       "Jersey                              61\n",
       "Saint Lucian                        47\n",
       "Pitcairn Islands                    43\n",
       "Chechen                             38\n",
       "East Timorese                       36\n",
       "Saint Kitts and Nevis               30\n",
       "Montserratian                       27\n",
       "Guernsey                            25\n",
       "Omani                               24\n",
       "Niuean                              22\n",
       "Carniolan                           22\n",
       "Saint Vincent and the Grenadines    21\n",
       "Palauan                             21\n",
       "South Ossetian                      18\n",
       "Tokelauan                           17\n",
       "Abkhazia                            16\n",
       "South African Republic              15\n",
       "Greenlandic                         13\n",
       "Ossetian                             9\n",
       "Incan                                7\n",
       "Dagestani                            7\n",
       "Somaliland                           4\n",
       "Rojava                               2\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all[d_all['Location'].isnull()]['country'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hong Kong, SAR                  1\n",
       "Channel Islands                 1\n",
       "St. Vincent & the Grenadines    1\n",
       "Timor-Leste                     1\n",
       "Macao, SAR                      1\n",
       "St. Kitts-Nevis                 1\n",
       "Puerto Rico                     1\n",
       "Guam                            1\n",
       "Palau                           1\n",
       "New Caledonia                   1\n",
       "Mayotte                         1\n",
       "Western Sahara                  1\n",
       "French Polynesia                1\n",
       "Reunion                         1\n",
       "Oman                            1\n",
       "St. Lucia                       1\n",
       "Brunei                          1\n",
       "Georgia                         1\n",
       "Curacao                         1\n",
       "Name: Location, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all[d_all['country'].isnull()]['Location'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Chad</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abdullah II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>498683267.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Chad</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salmama II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>565745353.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>Chad</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   page country       rev_id Score Location        Data\n",
       "0        Bir I of Kanem    Chad  355319463.0  Stub     Chad  13707000.0\n",
       "1  Abdullah II of Kanem    Chad  498683267.0  Stub     Chad  13707000.0\n",
       "2   Salmama II of Kanem    Chad  565745353.0  Stub     Chad  13707000.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that we've added in the additional remappings here, rows that still have a NaN 'Location' value are rows for which we have no population data and, per the assignment, we can get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46720, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(d_all['Location'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46128, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all.dropna(subset=['Location'], inplace=True)\n",
    "d_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did an outer join above so we could understand data without matches on both sides of the join, we also need to drop the rows with location/population data but with no matching articles. These rows have nulls for the page data fields - for page, country, rev_id, and Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46109, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all.dropna(subset=['page', 'country', 'rev_id', 'Score'], how='all', inplace=True)\n",
    "d_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll also get rid of any rows where we don't have score data - these can come from, for example as noted above, cases where the actual page has been deleted on Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>country</th>\n",
       "      <th>rev_id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Location</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9352</th>\n",
       "      <td>Jalal Movaghar</td>\n",
       "      <td>Iran</td>\n",
       "      <td>807367030.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iran</td>\n",
       "      <td>78483446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9353</th>\n",
       "      <td>Mohsen Movaghar</td>\n",
       "      <td>Iran</td>\n",
       "      <td>807367166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iran</td>\n",
       "      <td>78483446.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 page country       rev_id Score Location        Data\n",
       "9352   Jalal Movaghar    Iran  807367030.0   NaN     Iran  78483446.0\n",
       "9353  Mohsen Movaghar    Iran  807367166.0   NaN     Iran  78483446.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all[d_all['Score'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46107, 6)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all.dropna(subset=['Score'], inplace=True)\n",
    "d_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up columns to match assignment instructions: rename and drop extra join column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_name</th>\n",
       "      <th>country</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>article_quality</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bir I of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>355319463.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abdullah II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>498683267.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salmama II of Kanem</td>\n",
       "      <td>Chad</td>\n",
       "      <td>565745353.0</td>\n",
       "      <td>Stub</td>\n",
       "      <td>13707000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           article_name country  revision_id article_quality  population\n",
       "0        Bir I of Kanem    Chad  355319463.0            Stub  13707000.0\n",
       "1  Abdullah II of Kanem    Chad  498683267.0            Stub  13707000.0\n",
       "2   Salmama II of Kanem    Chad  565745353.0            Stub  13707000.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d_all['Location']\n",
    "d_all.rename(columns={'page':'article_name',\n",
    "                      'rev_id':'revision_id',\n",
    "                      'Score':'article_quality',\n",
    "                      'Data':'population'}, inplace=True)\n",
    "d_all[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Afghanistan    0.000010\n",
       "Albania        0.000158\n",
       "Algeria        0.000003\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_person = d_all.groupby(['country']).apply(lambda g: len(g) / g.iloc[0]['population'])\n",
    "articles_per_person[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3993892779252636e-06"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_person['United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00012628958316929483"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_person['Norway']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Nauru                             4.788214e-03\n",
       "Tuvalu                            4.576271e-03\n",
       "San Marino                        2.454545e-03\n",
       "Monaco                            1.050200e-03\n",
       "Liechtenstein                     7.452755e-04\n",
       "Marshall Islands                  6.727273e-04\n",
       "Iceland                           6.105892e-04\n",
       "Tonga                             6.098742e-04\n",
       "Andorra                           4.358974e-04\n",
       "Samoa                             3.913290e-04\n",
       "Federated States of Micronesia    3.495146e-04\n",
       "Grenada                           3.243243e-04\n",
       "Luxembourg                        3.127185e-04\n",
       "Antigua and Barbuda               2.666667e-04\n",
       "Kiribati                          2.645503e-04\n",
       "Maldives                          2.392303e-04\n",
       "Malta                             2.387099e-04\n",
       "Fiji                              2.283737e-04\n",
       "Seychelles                        2.262127e-04\n",
       "Vanuatu                           2.162162e-04\n",
       "Dominica                          1.764706e-04\n",
       "New Zealand                       1.705065e-04\n",
       "Albania                           1.580221e-04\n",
       "Solomon Islands                   1.511139e-04\n",
       "Norway                            1.262896e-04\n",
       "Guadeloupe                        1.203931e-04\n",
       "Montenegro                        1.156773e-04\n",
       "Estonia                           1.136967e-04\n",
       "French Guiana                     1.075697e-04\n",
       "Sao Tome and Principe             1.073784e-04\n",
       "                                      ...     \n",
       "Turkey                            4.449274e-06\n",
       "Kazakhstan                        4.445895e-06\n",
       "Yemen                             4.413360e-06\n",
       "Cameroon                          4.380976e-06\n",
       "Venezuela                         4.278250e-06\n",
       "Angola                            4.240000e-06\n",
       "Niger                             4.024473e-06\n",
       "Saudi Arabia                      3.738305e-06\n",
       "Nigeria                           3.734064e-06\n",
       "Japan                             3.444557e-06\n",
       "United States                     3.399389e-06\n",
       "Cote d'Ivoire                     3.135564e-06\n",
       "Eritrea                           3.076923e-06\n",
       "Algeria                           2.903775e-06\n",
       "Senegal                           2.859010e-06\n",
       "Brazil                            2.699010e-06\n",
       "Egypt                             2.660709e-06\n",
       "Sudan                             2.323653e-06\n",
       "Mozambique                        2.253652e-06\n",
       "Vietnam                           2.038945e-06\n",
       "Bangladesh                        2.001110e-06\n",
       "Congo, Dem. Rep. of               1.936182e-06\n",
       "Thailand                          1.719869e-06\n",
       "Zambia                            1.615624e-06\n",
       "Korea, North                      1.440980e-06\n",
       "Ethiopia                          1.029058e-06\n",
       "Uzbekistan                        8.948320e-07\n",
       "China                             8.258499e-07\n",
       "Indonesia                         8.250503e-07\n",
       "India                             7.495638e-07\n",
       "Length: 191, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_person.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_high_quality(score):\n",
    "    if (score == 'FA') | (score == 'GA'):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stub     23456\n",
       "Start    15103\n",
       "C         5685\n",
       "GA         862\n",
       "B          722\n",
       "FA         279\n",
       "Name: article_quality, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_all['article_quality'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    44966\n",
       "True      1141\n",
       "Name: article_quality, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(d_all['article_quality'].apply(is_high_quality)).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Afghanistan    0.059006\n",
       "Albania        0.010941\n",
       "Algeria        0.025862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define this instead of using a lambda, like above, so we can keep the lines around 80 chars wide\n",
    "# a lambda would be fine as the actual function is still pretty short/a single liner\n",
    "def get_high_quality_article_proportion(articles):\n",
    "    return sum(articles['article_quality'].apply(is_high_quality)) / len(articles)\n",
    "\n",
    "high_quality_articles_per_all_articles = d_all.groupby(['country']).apply(get_high_quality_article_proportion)\n",
    "high_quality_articles_per_all_articles[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Korea, North                      0.250000\n",
       "Romania                           0.131195\n",
       "Saudi Arabia                      0.127119\n",
       "Central African Republic          0.121212\n",
       "Guinea-Bissau                     0.100000\n",
       "Qatar                             0.100000\n",
       "Vietnam                           0.096257\n",
       "Bhutan                            0.090909\n",
       "Mauritania                        0.083333\n",
       "Ireland                           0.082011\n",
       "United States                     0.078755\n",
       "Singapore                         0.072464\n",
       "Guatemala                         0.072289\n",
       "Uzbekistan                        0.071429\n",
       "Palestinian Territory             0.067039\n",
       "Benin                             0.065934\n",
       "Syria                             0.062016\n",
       "Gabon                             0.061224\n",
       "United Kingdom                    0.060381\n",
       "Afghanistan                       0.059006\n",
       "Ukraine                           0.056667\n",
       "Vanuatu                           0.050000\n",
       "Congo, Dem. Rep. of               0.049296\n",
       "Jamaica                           0.048780\n",
       "Gambia                            0.048780\n",
       "Spain                             0.046804\n",
       "Egypt                             0.046414\n",
       "Panama                            0.046296\n",
       "Mongolia                          0.043478\n",
       "Philippines                       0.043222\n",
       "                                    ...   \n",
       "Solomon Islands                   0.000000\n",
       "Burundi                           0.000000\n",
       "Kiribati                          0.000000\n",
       "Sao Tome and Principe             0.000000\n",
       "Turkmenistan                      0.000000\n",
       "Kazakhstan                        0.000000\n",
       "Nepal                             0.000000\n",
       "Nauru                             0.000000\n",
       "Tonga                             0.000000\n",
       "Honduras                          0.000000\n",
       "Guyana                            0.000000\n",
       "Switzerland                       0.000000\n",
       "Zambia                            0.000000\n",
       "Tunisia                           0.000000\n",
       "Guadeloupe                        0.000000\n",
       "Swaziland                         0.000000\n",
       "French Guiana                     0.000000\n",
       "Cape Verde                        0.000000\n",
       "Lesotho                           0.000000\n",
       "Tajikistan                        0.000000\n",
       "Mozambique                        0.000000\n",
       "Eritrea                           0.000000\n",
       "Liechtenstein                     0.000000\n",
       "Suriname                          0.000000\n",
       "Dominica                          0.000000\n",
       "Djibouti                          0.000000\n",
       "Comoros                           0.000000\n",
       "Macedonia                         0.000000\n",
       "San Marino                        0.000000\n",
       "Federated States of Micronesia    0.000000\n",
       "Length: 191, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_quality_articles_per_all_articles.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we filter out countries with 'smaller' populations, what do we see for the same lists? First we'll add in the population data and then we can use that to filter the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportion</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>32247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.000158</td>\n",
       "      <td>2892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>39948000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             proportion  population\n",
       "Afghanistan    0.000010    32247000\n",
       "Albania        0.000158     2892000\n",
       "Algeria        0.000003    39948000"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_person = pd.concat([articles_per_person, \n",
    "           d_population[['Location','Data']].set_index('Location')['Data']],\n",
    "           axis=1).rename(columns={0:'proportion','Data':'population'})\n",
    "articles_per_person[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proportion</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>0.059006</td>\n",
       "      <td>32247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>0.010941</td>\n",
       "      <td>2892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.025862</td>\n",
       "      <td>39948000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             proportion  population\n",
       "Afghanistan    0.059006    32247000\n",
       "Albania        0.010941     2892000\n",
       "Algeria        0.025862    39948000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_quality_articles_per_all_articles = pd.concat([high_quality_articles_per_all_articles, \n",
    "           d_population[['Location','Data']].set_index('Location')['Data']],\n",
    "           axis=1).rename(columns={0:'proportion','Data':'population'})\n",
    "high_quality_articles_per_all_articles[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can look at the lists again, with a threshold population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_thresh = 50000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France                 2.612410e-05\n",
       "United Kingdom         1.450255e-05\n",
       "Italy                  1.319101e-05\n",
       "Iran                   1.046080e-05\n",
       "Germany                8.516985e-06\n",
       "Mexico                 8.479180e-06\n",
       "Tanzania               7.745119e-06\n",
       "Korea, South           7.394427e-06\n",
       "South Africa           6.867608e-06\n",
       "Russia                 6.077532e-06\n",
       "Pakistan               5.224889e-06\n",
       "Philippines            4.943413e-06\n",
       "Myanmar                4.544844e-06\n",
       "Turkey                 4.449274e-06\n",
       "Nigeria                3.734064e-06\n",
       "Japan                  3.444557e-06\n",
       "United States          3.399389e-06\n",
       "Brazil                 2.699010e-06\n",
       "Egypt                  2.660709e-06\n",
       "Vietnam                2.038945e-06\n",
       "Bangladesh             2.001110e-06\n",
       "Congo, Dem. Rep. of    1.936182e-06\n",
       "Thailand               1.719869e-06\n",
       "Ethiopia               1.029058e-06\n",
       "China                  8.258499e-07\n",
       "Indonesia              8.250503e-07\n",
       "India                  7.495638e-07\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_per_person[articles_per_person['population'] > pop_thresh].sort_values(by='proportion', ascending=False)['proportion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vietnam                0.096257\n",
       "United States          0.078755\n",
       "United Kingdom         0.060381\n",
       "Congo, Dem. Rep. of    0.049296\n",
       "Egypt                  0.046414\n",
       "Philippines            0.043222\n",
       "Indonesia              0.042654\n",
       "Russia                 0.039909\n",
       "Myanmar                0.037975\n",
       "China                  0.037070\n",
       "South Africa           0.031746\n",
       "Germany                0.027496\n",
       "Thailand               0.026786\n",
       "Iran                   0.020706\n",
       "Ethiopia               0.019802\n",
       "Bangladesh             0.018692\n",
       "Korea, South           0.018667\n",
       "France                 0.017847\n",
       "Japan                  0.016018\n",
       "India                  0.015228\n",
       "Pakistan               0.013462\n",
       "Turkey                 0.011494\n",
       "Italy                  0.009709\n",
       "Brazil                 0.009058\n",
       "Mexico                 0.006500\n",
       "Nigeria                0.005891\n",
       "Tanzania               0.002469\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_quality_articles_per_all_articles[high_quality_articles_per_all_articles['population'] > pop_thresh].sort_values(by='proportion', ascending=False)['proportion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_all.to_csv('en-wikipedia-politician-scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
